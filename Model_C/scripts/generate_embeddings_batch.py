#!/usr/bin/env python3
"""
æ‰¹é‡ç”Ÿæˆå…¨å±€åµŒå…¥å‘é‡CSVæ–‡ä»¶çš„è„šæœ¬
Generate Global Embeddings CSV File Script - Batch Version

æ­¤è„šæœ¬ä¸“é—¨ç”¨äºæå–æ¯ä¸ªæ¨¡å‹å¯¹æ¯ä¸ªææ–™çš„å…¨å±€åµŒå…¥å‘é‡ï¼Œ
å¹¶ä¿å­˜ä¸ºCSVæ ¼å¼ï¼Œæ–¹ä¾¿åç»­çš„çº¿æ€§éªŒè¯ã€‚

ç›´æ¥åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼Œé¿å…å¯¼å…¥è·¯å¾„é—®é¢˜ã€‚
"""

import torch
import numpy as np
import json
import os
import sys
import time
import warnings
from pathlib import Path
import pandas as pd
import argparse
import random

# è®¾ç½®Pythonè·¯å¾„å¹¶å¯¼å…¥æ¨¡å—
import os
import sys

# ç¡®ä¿å¯ä»¥å¯¼å…¥srcæ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
src_path = os.path.join(parent_dir, 'src')

if src_path not in sys.path:
    sys.path.insert(0, src_path)

def set_random_seed(seed=42):
    """è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯å¤ç°"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    print(f"âœ“ å·²è®¾ç½®éšæœºç§å­: {seed}")

try:
    from src.simplex_data_loader import PerovskiteSimplexDataset
    from src.snn_model import SNN, SNNHamiltonianDynamicsSDE
    print("âœ“ TEN-FMAæ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸ")
    print(f"ğŸ“‚ ä»è·¯å¾„å¯¼å…¥: {src_path}")
except ImportError as e:
    print("é”™è¯¯: æ— æ³•å¯¼å…¥å¿…è¦çš„æ¨¡å—ã€‚")
    print(f"è¯¦ç»†é”™è¯¯: {e}")
    print(f"å½“å‰Pythonè·¯å¾„: {sys.path}")
    sys.exit(1)


def load_pretrained_model(model_dir: str, device: torch.device) -> tuple[SNN, dict]:
    """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œå…¶é…ç½®"""
    model_path = Path(model_dir) / "pretrained_encoder.pt"
    config_path = Path(model_dir) / "pretrain_args.json"

    if not model_path.exists():
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    if not config_path.exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")

    # åŠ è½½é…ç½®
    with open(config_path, 'r') as f:
        config = json.load(f)

    # åˆ›å»ºæ•°æ®é›†è·å–ç‰¹å¾ç»Ÿè®¡
    dataset = PerovskiteSimplexDataset(data_root="data", load_triangles=True)
    stats = dataset.get_feature_stats()

    # åˆ›å»ºæ¨¡å‹
    snn_model = SNN(
        node_input_dim=stats['num_node_features'],
        edge_input_dim=stats['num_edge_features'],
        triangle_input_dim=stats.get('num_triangle_features', 0),
        hidden_dim=config['hidden_dim'],
        output_dim=config['output_dim'],
        num_layers=config['num_layers']
    ).to(device)

    # åŠ è½½é¢„è®­ç»ƒæƒé‡
    checkpoint = torch.load(model_path, map_location=device)

    # è¿‡æ»¤å‡ºå±äºSNNæ¨¡å‹çš„å‚æ•°ï¼ˆå»æ‰å‰ç¼€ï¼‰
    snn_state_dict = {}
    for key, value in checkpoint.items():
        if key.startswith('sde_module.snn_model.'):
            # ç§»é™¤å‰ç¼€
            new_key = key.replace('sde_module.snn_model.', '')
            snn_state_dict[new_key] = value

    # å°è¯•åŠ è½½ï¼Œå¦‚æœæœ‰ä¸åŒ¹é…çš„å‚æ•°å°±è·³è¿‡
    try:
        snn_model.load_state_dict(snn_state_dict, strict=False)
        print(f"âœ“ æˆåŠŸåŠ è½½ {len(snn_state_dict)} ä¸ªæ¨¡å‹å‚æ•°")
    except Exception as e:
        print(f"âš ï¸ å‚æ•°åŠ è½½è­¦å‘Š: {e}")
        # å°è¯•æ›´å®½æ¾çš„åŠ è½½
        missing_keys, unexpected_keys = snn_model.load_state_dict(snn_state_dict, strict=False)
        if missing_keys:
            print(f"  ç¼ºå¤±å‚æ•°: {len(missing_keys)}")
        if unexpected_keys:
            print(f"  å¤šä½™å‚æ•°: {len(unexpected_keys)}")
    snn_model.eval()

    print(f"âœ“ æˆåŠŸåŠ è½½æ¨¡å‹: {model_dir}")
    return snn_model, config


def run_static_embedding_extraction(model: SNN, data, device: torch.device):
    """ç›´æ¥ä½¿ç”¨SNNæ¨¡å‹æå–é™æ€åµŒå…¥å‘é‡"""
    model.eval()
    model.to(device)
    data = data.to(device)
    with torch.no_grad():
        _, global_embedding = model(data)
    return global_embedding.cpu()


def run_hamiltonian_dynamics(model: SNNHamiltonianDynamicsSDE, data, device: torch.device):
    """è¿è¡Œå“ˆå¯†é¡¿åŠ¨åŠ›å­¦å¹¶è¿”å›ç»“æœ"""
    model.eval()
    model.to(device)

    with torch.no_grad():
        q_final, p_final, hamiltonian_history, kinetic_history, potential_history, trajectory_history = model(data)

        # è·å–æœ€ç»ˆçš„å…¨å±€åµŒå…¥å‘é‡
        final_data = data.clone()
        final_data.pos = q_final
        _, global_embedding = model.sde_module.snn_model(final_data)

    return (q_final.cpu(), p_final.cpu(), hamiltonian_history,
            kinetic_history, potential_history, trajectory_history.cpu(), global_embedding.cpu())


def extract_embeddings_for_materials(model_dir: str, materials: list, device: torch.device = None):
    """ä¸ºæŒ‡å®šææ–™æå–å…¨å±€åµŒå…¥å‘é‡"""
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    print(f"\nğŸ”¬ å¼€å§‹æå–æ¨¡å‹ {model_dir} çš„åµŒå…¥å‘é‡ (é™æ€æ¨¡å¼)")
    print(f"ææ–™åˆ—è¡¨: {', '.join(materials)}")

    try:
        # 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        snn_model, config = load_pretrained_model(model_dir, device)

        # 2. åˆ›å»ºæ•°æ®é›†
        dataset = PerovskiteSimplexDataset(data_root="data", load_triangles=True)
        if len(dataset) == 0:
            print("âœ— é”™è¯¯: æ•°æ®é›†ä¸­æ²¡æœ‰æ ·æœ¬")
            return []

        embeddings_data = []

        for material in materials:
            print(f"ğŸ“Š å¤„ç†ææ–™: {material}")

            # é€‰æ‹©æŒ‡å®šçš„ææ–™
            test_sample = None
            for i in range(len(dataset)):
                sample = dataset.get(i)
                if hasattr(sample, 'material_name') and sample.material_name == material:
                    test_sample = sample
                    break

            if test_sample is None:
                print(f"âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°ææ–™ '{material}'ï¼Œè·³è¿‡")
                continue

            data = test_sample.to(device)
            actual_material = getattr(data, 'material_name', 'Unknown')

            # æ–¹æ¡ˆBæ ¸å¿ƒæ”¹åŠ¨ï¼šç›´æ¥è°ƒç”¨SNNæ¨¡å‹ï¼Œç»•è¿‡SDE
            start_time = time.time()
            global_embedding = run_static_embedding_extraction(snn_model, data, device)
            computation_time = time.time() - start_time

            # ç§»é™¤SDEç›¸å…³çš„å®ˆæ’åˆ†æ•°è®¡ç®—
            # hamiltonian_array = np.array(hamiltonian_history)
            # hamiltonian_mean = np.mean(hamiltonian_array)
            # hamiltonian_std = np.std(hamiltonian_array)
            # conservation_score = hamiltonian_std / abs(hamiltonian_mean) if hamiltonian_mean != 0 else float('inf')

            # 6. ä¿å­˜åµŒå…¥å‘é‡æ•°æ®
            embedding_data = {
                'material': actual_material,
                'embedding': global_embedding,
                # 'conservation_score': conservation_score, # ç§»é™¤
                'computation_time': computation_time
            }

            embeddings_data.append(embedding_data)
            print(f"   âœ“ å®Œæˆï¼Œè€—æ—¶: {computation_time:.4f}s")

        return embeddings_data

    except Exception as e:
        print(f"âœ— åµŒå…¥å‘é‡æå–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return []


def save_embeddings_to_csv(model_dir: str, embeddings_data: list, output_dir: str = "embeddings"):
    """
    ä¿å­˜å…¨å±€åµŒå…¥å‘é‡åˆ°CSVæ–‡ä»¶

    Args:
        model_dir: æ¨¡å‹ç›®å½•å
        embeddings_data: åµŒå…¥å‘é‡æ•°æ®åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
    """
    Path(output_dir).mkdir(exist_ok=True)

    # å‡†å¤‡æ•°æ®
    csv_data = []
    embedding_dim = None

    for data in embeddings_data:
        material = data['material']
        embedding = data['embedding'].cpu().numpy().flatten()
        # conservation_score = data['conservation_score'] # ç§»é™¤
        computation_time = data['computation_time']

        if embedding_dim is None:
            embedding_dim = len(embedding)

        # åˆ›å»ºä¸€è¡Œæ•°æ®ï¼šææ–™å + è®¡ç®—æ—¶é—´ + åµŒå…¥å‘é‡
        row = {
            'material': material,
            # 'conservation_score': conservation_score, # ç§»é™¤
            'computation_time': computation_time,
            'model': model_dir
        }

        # æ·»åŠ åµŒå…¥å‘é‡çš„æ¯ä¸ªç»´åº¦
        for i, val in enumerate(embedding):
            row[f'emb_{i}'] = val

        csv_data.append(row)

    if not csv_data:
        print("âš ï¸ æ²¡æœ‰åµŒå…¥å‘é‡æ•°æ®å¯ä¿å­˜")
        return None

    # åˆ›å»ºDataFrameå¹¶ä¿å­˜
    df = pd.DataFrame(csv_data)
    output_path = Path(output_dir) / f"{model_dir}_embeddings.csv"

    df.to_csv(output_path, index=False, float_format='%.6f')
    print(f"âœ“ å…¨å±€åµŒå…¥å‘é‡å·²ä¿å­˜è‡³: {output_path}")
    print(f"   æ•°æ®å½¢çŠ¶: {len(csv_data)} è¡Œ Ã— {len(df.columns)} åˆ—")
    print(f"   åµŒå…¥ç»´åº¦: {embedding_dim}")

    return output_path


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="TEN-FMAå…¨å±€åµŒå…¥å‘é‡æå–å·¥å…·")
    parser.add_argument('--model1', type=str, default='model-1-09171648',
                       help='ç¬¬ä¸€ä¸ªæ¨¡å‹ç›®å½•å')
    parser.add_argument('--model2', type=str, default='model-2-09180905',
                       help='ç¬¬äºŒä¸ªæ¨¡å‹ç›®å½•å')
    parser.add_argument('--model3', type=str, default='model-3-09181323',
                       help='ç¬¬ä¸‰ä¸ªæ¨¡å‹ç›®å½•å')
    parser.add_argument('--model4', type=str, default='model-4-09181820',
                       help='ç¬¬å››ä¸ªæ¨¡å‹ç›®å½•å')
    parser.add_argument('--materials', type=str, nargs='+',
                       help='è¦æå–åµŒå…¥å‘é‡çš„ææ–™åç§°')
    parser.add_argument('--all-materials', action='store_true',
                       help='æå–æ‰€æœ‰5ä¸ªææ–™çš„åµŒå…¥å‘é‡ (CsPbCl3, CsPbBr3, CH3NH3GeI3, CH3NH3PbI3, CsPbI3)')
    parser.add_argument('--output-dir', type=str, default='embeddings',
                       help='è¾“å‡ºç›®å½• (ç›¸å¯¹äºæ¨¡å‹ç›®å½•)')
    parser.add_argument('--device', type=str, default=None,
                       help='è®¡ç®—è®¾å¤‡ (cuda/cpu/auto)')

    args = parser.parse_args()

    # è®¾ç½®éšæœºç§å­
    set_random_seed(42)

    print("ğŸ¯ TEN-FMAå…¨å±€åµŒå…¥å‘é‡æå–å·¥å…·")
    print("="*60)

    # è®¾ç½®è®¾å¤‡
    if args.device == 'cuda':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    elif args.device == 'cpu':
        device = torch.device('cpu')
    else:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    if torch.cuda.is_available() and device.type == 'cuda':
        print(f"CUDAè®¾å¤‡: {torch.cuda.get_device_name(device)}")

    # ç¡®å®šææ–™åˆ—è¡¨
    if args.all_materials:
        materials = ['CsPbCl3', 'CsPbBr3', 'CH3NH3GeI3', 'CH3NH3PbI3', 'CsPbI3']
        print(f"ğŸ“‹ å¤„ç†æ‰€æœ‰5ä¸ªææ–™: {', '.join(materials)}")
    elif args.materials:
        materials = args.materials
        print(f"ğŸ“‹ å¤„ç†æŒ‡å®šææ–™: {', '.join(materials)}")
    else:
        print("âŒ é”™è¯¯: è¯·ä½¿ç”¨ --materials æŒ‡å®šææ–™æˆ–ä½¿ç”¨ --all-materials å¤„ç†æ‰€æœ‰ææ–™")
        parser.print_help()
        sys.exit(1)

    # å¤„ç†æ¯ä¸ªæ¨¡å‹
    all_embeddings_data = []

    for model_dir in [args.model1, args.model2, args.model3, args.model4]:
        if not Path(model_dir).exists():
            print(f"âš ï¸ è­¦å‘Š: æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_dir}")
            continue

        # æå–åµŒå…¥å‘é‡
        embeddings_data = extract_embeddings_for_materials(model_dir, materials, device)

        if embeddings_data:
            # ä¿å­˜åˆ°CSV
            model_short_name = Path(model_dir).name
            embeddings_dir = Path(model_dir) / args.output_dir
            csv_path = save_embeddings_to_csv(model_short_name, embeddings_data, str(embeddings_dir))

            all_embeddings_data.extend(embeddings_data)

            print(f"âœ… æ¨¡å‹ {model_short_name} å¤„ç†å®Œæˆ")
        else:
            print(f"âŒ æ¨¡å‹ {model_dir} å¤„ç†å¤±è´¥")

    # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
    print(f"\n{'='*60}")
    print("ğŸ“Š åµŒå…¥å‘é‡æå–å®Œæˆæ€»ç»“:")
    print(f"{'='*60}")

    if all_embeddings_data:
        total_materials = len(set([d['material'] for d in all_embeddings_data]))
        total_models = len(set([Path(d.get('model', '')).name for d in all_embeddings_data if d.get('model')]))

        print(f"âœ… æˆåŠŸæå–: {len(all_embeddings_data)} ä¸ªåµŒå…¥å‘é‡")
        print(f"   æ¶µç›–ææ–™: {total_materials} ä¸ª")
        print(f"   æ¶µç›–æ¨¡å‹: {total_models} ä¸ª")

        # ç§»é™¤å®ˆæ’åˆ†æ•°ç»Ÿè®¡
        # print("\nğŸ“ˆ å®ˆæ’åˆ†æ•°ç»Ÿè®¡:")
        # material_scores = {}
        # for data in all_embeddings_data:
        #     material = data['material']
        #     score = data['conservation_score']
        #     if material not in material_scores:
        #         material_scores[material] = []
        #     material_scores[material].append(score)
        #
        # for material, scores in material_scores.items():
        #     avg_score = np.mean(scores)
        #     min_score = np.min(scores)
        #     print(f"   - {material:<15}: å¹³å‡å®ˆæ’åˆ†æ•°={avg_score:.6f} (è¶Šå°è¶Šå¥½), æœ€å°={min_score:.6f}")

        print(f"\nğŸ’¾ CSVæ–‡ä»¶ä¿å­˜åœ¨å„ä¸ªæ¨¡å‹ç›®å½•çš„ {args.output_dir}/ æ–‡ä»¶å¤¹ä¸­")
        print("ğŸ¯ ç°åœ¨å¯ä»¥ä½¿ç”¨è¿™äº›CSVæ–‡ä»¶è¿›è¡Œçº¿æ€§éªŒè¯ï¼")
    else:
        print("âŒ æœªæå–åˆ°ä»»ä½•åµŒå…¥å‘é‡")


if __name__ == "__main__":
    main()
